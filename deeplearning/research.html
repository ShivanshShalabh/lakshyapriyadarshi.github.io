<! Article created by Lakshya Priyadarshi, contact at lakshya@abstractions.dev>
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
   <script>
      document.addEventListener("DOMContentLoaded", function() {
          renderMathInElement(document.body, {
          });
      });
   </script>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
      <meta name="author" content="Lakshya Priyadarshi" />
      <title>Deep Learning Research</title>
      <link href="stylesheet.css" rel="stylesheet" type="text/css" media="screen" />
      <link rel="shortcut icon" href="https://img.icons8.com/ios-filled/100/000000/informatics.png" />
      <script type="text/javascript" src="home.js"></script>
      <link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
      <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.0/jquery.min.js"></script>
      <style>
         a:link  {
         text-decoration: none;
         }
         body    {
         font-family: "Computer Modern Serif", sans-serif;
         }
         p       {
         text-align:justify;
         font-size: 20px;
         font-weight: 500;
         } 
         ol       {
         text-align:justify;
         font-size: 20px;
         font-weight: 500;
         } 
         body {
         }
         .wrapper {
         margin: 0 auto;
         width: 90%;
         padding-bottom: -5px;
         }
         .blockquote {
         background: white;
         padding: 10px 10px 10px 10px;
         margin: 50px auto;
         width: 50%;
         max-width: 500px;
         }
         .rule {
         position: relative;
         left: 7px;
         background: #e0e0e0;
         box-shadow: -2px 0 0 #0000FF, -4px 0 0 #ccccff, -7px 0 0 #0000FF;
         color:black;
         }
      </style>
   </head>
   <body onmousedown="return false" onselectstart="return false">
   	    <script>
      $(document).ready(function() {
          $("body").on("contextmenu", function(e) {
              return false;
            });
        });
    </script>
      <div class="main">
      <div id="intro_text" >
         <h1>
            First steps into deep learning research?<span style="font-size:20px; font-weight: 500;"><i> &nbsp;an introduction aimed at undergraduate students.</i></span>&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;<a href="https://twitter.com/abstractionsdev?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @abstractionsdev</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
         </h1>
         <hr>
         <p ><a href="https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf" target="_blank" rel="noopener noreferrer">Deep learning</a> is at the cornerstone of modern machine learning methods in <a href="https://www.oreilly.com/content/a-look-at-deep-learning-for-science/" target="_blank" rel="noopener noreferrer">fundamental sciences</a> and <a href="https://adeshpande3.github.io/adeshpande3.github.io/The-Last-5-Years-in-Deep-Learning" target="_blank" rel="noopener noreferrer">information technologies</a>. The interest in the field resurged in the <a href="http://people.idsia.ch/~juergen/2010s-our-decade-of-deep-learning.html" target="_blank" rel="noopener noreferrer">last decade</a> and drove <a href="https://bmk.sh/2019/12/31/The-Decade-of-Deep-Learning/" target="_blank" rel="noopener noreferrer">significant breakthroughs</a> in the design and development of learning algorithms, model architectures, and hardware <a href="http://eyeriss.mit.edu/tutorial.html" target="_blank" rel="noopener noreferrer">accelerators</a>. These developments are proving to be the inflection point in solving complex tasks like <a href="https://ai.facebook.com/blog/facebook-research-at-cvpr-2020/" target="_blank" rel="noopener noreferrer">visual perception and recognition</a>, <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" target="_blank" rel="noopener noreferrer">natural language processing</a>, <a href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html" target="_blank" rel="noopener noreferrer">conversational artificial intelligence</a>, <a href="https://deepmind.com/research/publications/Acme" target="_blank" rel="noopener noreferrer">agent-based modeling and control</a>, and <a href="https://research.google/pubs/pub46570/" target="_blank" rel="noopener noreferrer">robotics</a>. As a result, <i>applications act as feedback to research</i> and push the field further into discovery. The <a href="http://www.cis.jhu.edu/~rvidal/talks/learning/Tutorial-Math-Deep-Learning-2018.pdf" target="_blank" rel="noopener noreferrer">theoretical foundations</a> of deep learning continue to  evolve and probe deeper issues such as <a href="http://myaooo.com/#research" target="_blank" rel="noopener noreferrer">explainability</a>, <a href="https://arxiv.org/pdf/1812.06369.pdf" target="_blank" rel="noopener noreferrer">expressiveness</a>, and <a href="https://arxiv.org/pdf/1611.03530.pdf" target="_blank" rel="noopener noreferrer">generalization</a>. This builds a fertile ground for researching the <a href="https://learning.acm.org/techtalks/powerandlimitsdl" target="_blank" rel="noopener noreferrer">capabilities and limits</a> of deep learning and discovering new possibilities in a diverse range of intersecting disciplines such as <a href="https://www.embopress.org/doi/pdf/10.15252/msb.20156651" target="_blank" rel="noopener noreferrer">computational biology</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7115933/" target="_blank" rel="noopener noreferrer">neuroscience</a>, <a href="https://www.youtube.com/watch?v=5rk4NcYk3Vg" target="_blank" rel="noopener noreferrer">information theory</a>, <a href="https://arxiv.org/pdf/1806.09729.pdf" target="_blank" rel="noopener noreferrer">quantum computing</a>, and <a href="http://geometricdeeplearning.com/" target="_blank" rel="noopener noreferrer">geometry</a>.</p>
         <p>To grasp the deeper implications of emerging paradigms like <a href="https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html" target="_blank" rel="noopener noreferrer">self-supervised learning</a> and <a href="https://deepmind.com/blog/article/deep-reinforcement-learning" target="_blank" rel="noopener noreferrer">deep reinforcement learning</a> or models such as <a href="https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/" target="_blank" rel="noopener noreferrer">GPT-3</a> or <a href="https://arxiv.org/pdf/2007.14062.pdf" target="_blank" rel="noopener noreferrer">BigBird</a> requires a strong and clear understanding of <a href="https://www.youtube.com/watch?v=aircAruvnKk" target="_blank" rel="noopener noreferrer">deep learning fundamentals</a>. As the field progresses at a super-exponential rate, it becomes difficult for undergraduate students to transparently process the underlying aspects of <a href="https://www.youtube.com/watch?v=azOmzumh0vQ&t=157s" target="_blank" rel="noopener noreferrer">deep learning research</a>. In this letter, I have attempted to plot the trajectory for a deep learning course where the learning curve starts from bare fundamentals and touches the arc of state-of-the-art research. I have tried to cover <a href="https://mml-book.github.io/" target="_blank" rel="noopener noreferrer">basic mathematics</a>, <a href="https://www.springer.com/gp/book/9783319944623" target="_blank" rel="noopener noreferrer">foundations and theory</a>, <a href="http://d2l.ai/" target="_blank" rel="noopener noreferrer">implementation aspects</a>, and exposure to building science and technology applications. This learning path is largely based on my own experience with deep learning and is entirely constructed out of learning materials from esteemed practitioners. If you comprehensively follow this learning path, you could potentially arrive at the research frontiers of deep learning in six to ten months. The outline is (i) prerequisites, (ii) textbooks, (iii) courses, (iv) research papers, (v) implementation, (vi) exploratory reading, (vii) advanced frontiers, and (viii) executing research. </p>
         <hr>
         <p><b>Prerequisites:</b>
            The core component of <a href="https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning" target="_blank" rel="noopener noreferrer">deep learning</a> is applied mathematics: linear algebra, calculus, statistics, probability theory, information theory, numerical computation, and optimization; covered by the textbook ‘<a href="https://mml-book.github.io/book/mml-book.pdf" target="_blank" rel="noopener noreferrer">Mathematics for Machine Learning</a>’. A basic understanding of machine learning is necessary and is covered by <a href="https://alex.smola.org/drafts/thebook.pdf" target="_blank" rel="noopener noreferrer">Alex Smola's monograph</a>. Proficiency in deep learning frameworks like <a href="https://github.com/chiphuyen/stanford-tensorflow-tutorials" target="_blank" rel="noopener noreferrer">TensorFlow</a> or <a href="https://github.com/yunjey/pytorch-tutorial" target="_blank" rel="noopener noreferrer">PyTorch</a> is required for building large-scale deep learning systems, and a <a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture15.pdf" target="_blank" rel="noopener noreferrer">basic understanding of hardware</a> may be useful. As you delve deeper, more specialized prerequisites will emerge. In my experience, <i>self-learning is highly nonlinear, distributed, and iterative;</i> you may <i>start now</i> with <i>minimal functional knowledge</i> and learn incrementally.  
         </p>
         <hr>
         <!SDE, cloud, application domain knowledge, http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf bishop>
         <p><b>Structured learning:</b>
            At this point, you might have a <a href="https://arxiv.org/pdf/1904.05526.pdf" target="_blank" rel="noopener noreferrer">selective overview</a> of the vast contours of deep learning; and may proceed towards systematically understanding its fine details. The textbook ‘<a href="https://www.springer.com/gp/book/9783319944623" target="_blank" rel="noopener noreferrer">Neural Networks and Deep Learning</a>’ by <a href="https://dl.acm.org/profile/81350594201" target="_blank" rel="noopener noreferrer">Charu. C. Aggarwal</a> is a comprehensive document that covers the theory of modern deep neural networks, learning algorithms, various neural architectures, and issues in training deep networks; along with some recent developments in variational autoencoders, attention mechanisms, generative adversarial networks, neural Turing machines, and deep reinforcement learning. It also discusses some less-prevalent architectures such as radial basis function networks, restricted Boltzmann machines, and Kohonen self-organizing maps. Another comprehensive document centered around deep learning research is the seminal textbook ‘<a href="https://www.deeplearningbook.org/" target="_blank" rel="noopener noreferrer">Deep Learning</a>’ by <a href="http://www.iangoodfellow.com/slides/" target="_blank" rel="noopener noreferrer">Goodfellow</a>, <a href="https://mila.quebec/en/person/bengio-yoshua/" target="_blank" rel="noopener noreferrer">Bengio</a>, and <a href="https://mila.quebec/en/person/aaron-courville/" target="_blank" rel="noopener noreferrer">Courville</a>; it covers chapters about linear factor models, representation learning, probabilistic models, and generative models. Reading these books cover-to-cover will build a concrete foundation for research, and you may advance to implementing deep learning algorithms and start reading research papers.
         </p>
         <p><b>Classroom courses:</b>
            If you are not pursuing a university course in deep learning, you can build foundations through Hugo Larochelle’s <a href="http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html" target="_blank" rel="noopener noreferrer">Sherbrooke course</a> or Yann LeCun’s <a href="https://atcold.github.io/pytorch-Deep-Learning/" target="_blank" rel="noopener noreferrer">NYU course</a>, and refer to Stanford’s <a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv" target="_blank" rel="noopener noreferrer">computer vision</a> and <a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6" target="_blank" rel="noopener noreferrer">natural language processing</a> tutorials. You may refer to 
            John Canny’s <a href="https://bcourses.berkeley.edu/courses/1453965" target="_blank" rel="noopener noreferrer">UCB course</a> for advanced topics like practical issues in training networks, distributed deep learning, and neural computing; and to <a href="http://introtodeeplearning.com/" target="_blank" rel="noopener noreferrer">MIT 6.S191 course</a> for neural rendering, and neurosymbolic hybrid systems. As you proceed, you can selectively learn from research-intensive courses such as Joan Bruna’s <a href="https://joanbruna.github.io/stat212b/" target="_blank" rel="noopener noreferrer">UCB course</a> on building stable representations for high-dimensional data; and David Duvenaud’s <a href="http://www.cs.toronto.edu/~duvenaud/courses/csc2541/" target="_blank" rel="noopener noreferrer">UoT course</a> on differentiable inference and generative models.
         </p>
         <hr>
         <div class="wrapper">
            <blockquote class="rule">
               <p>&ensp;&ensp;<i>‘‘I was an ordinary person who studied hard.’’</i> - <a href="https://www.feynmanlectures.caltech.edu/"target="_blank" rel="noopener noreferrer">@richardfeynman</a>, <i>hypergenius theoretical physicist</i></p>
            </blockquote>
         </div>
         <hr>
         <p><b>Reading research papers: </b>
            The standard procedure in academic research to acquire knowledge about a specific area is to read a sequence of connected references until you reach the first principles. Reading <a href="https://jeffhuang.com/best_paper_awards/" target="_blank" rel="noopener noreferrer">papers</a> is an <i>excursion into the minds of scientists</i> as you can connect to a diverse range of science problems, learn different approaches to tackle them, understand the motivation and design of a particular solution, and build a mental model for research. Since deep learning literature continuously <a href="https://arxiv.org/list/cs.LG/recent" target="_blank" rel="noopener noreferrer">expands in breadth and depth</a>, you may adopt a <a href="https://www.youtube.com/watch?v=733m6qBH-jI" target="_blank" rel="noopener noreferrer">targeted approach</a> to reading: (i) select a researcher or a subdomain, (ii) start with <a href="https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap" target="_blank" rel="noopener noreferrer">landmark papers</a>, and (iii) <a href="https://www.zotero.org/" target="_blank" rel="noopener noreferrer">keep track</a> of ‘state-of-the-art’ via <a href="https://paperswithcode.com/sota" target="_blank" rel="noopener noreferrer">paperswithcode</a>, <a href="http://www.arxiv-sanity.com/" target="_blank" rel="noopener noreferrer">arxiv-sanity-preserver</a>, <a href="http://paperreading.club/" target="_blank" rel="noopener noreferrer">paperreading.club</a>, and conferences such as <a href="https://nips.cc/" target="_blank" rel="noopener noreferrer">NIPS</a>, <a href="https://iclr.cc//" target="_blank" rel="noopener noreferrer">ICLR</a>, <a href="https://www.aaai.org/Conferences/conferences.php" target="_blank" rel="noopener noreferrer">AAAI</a>, <a href="https://icml.ccp" target="_blank" rel="noopener noreferrer">ICML</a>. Document your learning with <a href="https://shagunsodhani.com/papers-I-read/" target="_blank" rel="noopener noreferrer">detailed notes</a>, write monographs or <a href="https://distill.pub/prize/" target="_blank" rel="noopener noreferrer">explanatory articles</a>, and communicate your knowledge by teaching others. To that end, you can organize paper-reading sessions like <a href="https://paperswelove.org/" target="_blank" rel="noopener noreferrer">paperswelove</a>, discuss the ‘<a href="https://paperswithcode.com/sota" target="_blank" rel="noopener noreferrer">state-of-the-art</a>’ in deep learning, and present a seminar on a particular development. This will enhance your conceptual understanding and will immensely refine you as a researcher.
         </p>
         <p><b>Implementation:</b> Programming is crucial as you traverse through the textbooks. The companion reference ‘<a href="http://d2l.ai/chapter_preface/index.html#content-and-structure" target="_blank" rel="noopener noreferrer">Dive into Deep Learning</a>’ methodologically covers the implementation of deep learning algorithms via MXNet, TensorFlow, and PyTorch frameworks; you may start by implementing simple <a href="https://www.mladdict.com/neural-network-simulator" target="_blank" rel="noopener noreferrer">feedforward neural networks</a> and progressively implement specialized deep architectures for applications in computer vision, natural language processing, and recommender systems. You may subsequently follow the course ‘<a href="https://www.fast.ai/2019/06/28/course-p2v3/" target="_blank" rel="noopener noreferrer">Deep Learning from the Foundations</a>’ which recreates the <a href="https://course.fast.ai/" target="_blank" rel="noopener noreferrer">fast.ai course</a> from scratch and discusses a set of selective research papers. This practice not only strengthens your algorithmic fundamentals, but also exposes you to practical issues such as optimization choices, convergence problems, stability of networks, and hardware constraints. At this point, you may start implementing research papers, try to replicate the results, and think about reinventing the solution. It is advantageous to connect with the concerned researchers or their graduate students who can supervise and direct you further: this could possibly be your first research contribution and might yield a publication or conference paper.</p>
         <hr>
         <p><b>Visual learning:</b>
            The basic principle of <a href="https://www.asimovinstitute.org/neural-network-zoo/" target="_blank" rel="noopener noreferrer">neural networks</a> is simple: parametrized models structured as hierarchical computation graphs learn distributed representations in order to approximate non-linear functions. However, it is difficult <i>for us</i> to describe computations in deep neural networks. Interactive <a href="https://poloclub.github.io/#research-ai" target="_blank" rel="noopener noreferrer">tools</a> for simple <a href="https://playground.tensorflow.org/" target="_blank" rel="noopener noreferrer">neural networks</a>, <a href="https://github.com/tensorflow/tensorboard/blob/master/docs/graphs.ipynb" target="_blank" rel="noopener noreferrer">computation graphs</a>, <a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html" target="_blank" rel="noopener noreferrer">binary classification</a>, <a href="https://poloclub.github.io/cnn-explainer/" target="_blank" rel="noopener noreferrer">convolutional networks</a>, <a href="http://myaooo.com/projects/rnnvis/" target="_blank" rel="noopener noreferrer">recurrent networks</a>, and <a href="https://poloclub.github.io/ganlab/" target="_blank" rel="noopener noreferrer">generative adversarial networks</a> build <a href="https://fredhohman.com/visual-analytics-in-deep-learning/" target="_blank" rel="noopener norefrer">visual abstractions</a> that simplify the process of <a href="https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network">understanding deep learning</a>. To that end, tools like <a href="https://pair-code.github.io/saliency/" target="_blank" rel="noopener noreferrer">sensitivity masks</a>, <a href="https://fredhohman.com/summit/" target="_blank" rel="noopener noreferrer">attribution graphs</a>, <a href="https://idl.cs.washington.edu/papers/tfgraph/" target="_blank" rel="noopener noreferrer">dataflow graphs</a>, <a href="http://projector.tensorflow.org/" target="_blank" rel="noopener noreferrer">embedding projector</a>, and <a href="https://seq2seq-vis.io/" target="_blank" rel="noopener noreferrer">seq2seq-vis</a> are driving the <a href="https://minsuk.com/research/activis/" target="_blank" rel="noopener noreferrer">visual exploration of deep networks</a> and augmenting research in <a href="https://medium.com/multiple-views-visualization-research-explained/visualization-in-deep-learning-b29f0ec4f136" target="_blank" rel="noopener noreferrer">model interpretability</a>.<br>
         </p>
         <!img src="zoo.png" alt="Italian Trulli" style="max-width: 100%;margin: auto;">
         <p><b>Explanatory blogs:</b>
            State-of-the-art research sometimes involves techniques that are difficult to absorb and assimilate as an undergraduate student. For example, the related mathematics could be opaque or central ideas could involve concepts from interdisciplinary domains such as <a href="https://jaan.io/how-does-physics-connect-machine-learning/" target="_blank" rel="noopener noreferrer">physics</a> or <a href="https://www.youtube.com/watch?v=tg_m_LxxRwM" target="_blank" rel="noopener noreferrer">neuroscience</a>. In such cases, you should read explanatory blogs that deconstruct and simplify complex ideas into transparent and accessible ones. Some of the ones I have found to be particularly useful are <a href="https://colah.github.io/" target="_blank" rel="noopener noreferrer">colah</a>, <a href="https://distill.pub/" target="_blank" rel="noopener noreferrer">distill</a>, <a href="http://gradientscience.org/" target="_blank" rel="noopener noreferrer">gradientscience</a>, <a href="https://www.offconvex.org/" target="_blank" rel="noopener noreferrer">offconvex</a>, <a href="https://losslandscape.com/" target="_blank" rel="noopener noreferrer">losslandscape</a>, <a href="https://explained.ai/" target="_blank" rel="noopener noreferrer">explained</a>, <a href="https://jalammar.github.io/" target="_blank" rel="noopener noreferrer">jalammar</a>, <a href="http://www.depthfirstlearning.com/" target="_blank" rel="noopener noreferrer">depthfirstlearning</a>, <a href="https://www.inference.vc/" target="_blank" rel="noopener noreferrer">inference</a>, <a href="https://r2rt.com/" target="_blank" rel="noopener noreferrer">r2rt</a>, <a href="https://lilianweng.github.io/lil-log/" target="_blank" rel="noopener noreferrer">lil-log</a>, <a href="http://blog.echen.me/" target="_blank" rel="noopener noreferrer">echen</a>, <a href="https://adeshpande3.github.io/adeshpande3.github.io/" target="_blank" rel="noopener noreferrer">adit</a>, <a href="https://shapeofdata.wordpress.com/category/neural-networks/" target="_blank" rel="noopener noreferrer">shapeofdata</a>, <a href="https://minimizingregret.wordpress.com/blog/" target="_blank" rel="noopener noreferrer">minimizingregret</a>, <a href="http://www.argmin.net/" target="_blank" rel="noopener noreferrer">argmin</a>, <a href="https://www.youtube.com/user/keeroyz" target="_blank" rel="noopener noreferrer">two-minute-papers</a>, and <a href="https://www.youtube.com/c/ArxivInsights/videos" target="_blank" rel="noopener noreferrer">arxiv-insights</a>. The explanations, analogies, and visualizations presented in these blogs are resourceful in  building deep insights and intuitions about relatively abstract concepts as described in the standard deep learning literature.
         </p>
         <hr>
         <p><b>Exploratory reading:</b>
            As time <a href="https://arxiv.org/pdf/1702.07800.pdf" target="_blank" rel="noopener noreferrer">evolves</a>, scientists and engineers are <a href="https://www.cs.tau.ac.il/~wolf/deeplearningmeeting/pdfs/lecun-20141105-tau-intel-master-class.pdf" target="_blank" rel="noopener noreferrer">investigating</a> new and interesting ways in which deep learning can be used to approach extremely complex problems. An effective way of discovering such research and understanding its implications in a particular technology domain is by reading research expositions from <a href="https://ai.googleblog.com/" target="_blank" rel="noopener noreferrer">Google AI</a>, <a href="https://deepmind.com/blog" target="_blank" rel="noopener noreferrer">DeepMind</a>, <a href="https://openai.com/blog/" target="_blank" rel="noopener noreferrer">OpenAI</a>, <a href="https://ai.facebook.com/blog/" target="_blank" rel="noopener noreferrer">FAIR</a>, <a href="https://www.nvidia.com/en-us/research/" target="_blank" rel="noopener noreferrer">Nvidia</a>, <a href="https://www.ibm.com/blogs/research/tag/deep-learning/" target="_blank" rel="noopener noreferrer">IBM</a>,  <a href="https://machinelearning.apple.com/" target="_blank" rel="noopener noreferrer">ML@Apple</a>, <a href="https://www.microsoft.com/en-us/research/blog/" target="_blank" rel="noopener noreferrer">Microsoft</a>, <a href="https://www.amazon.science/blog" target="_blank" rel="noopener noreferrer">Amazon Science</a>, <a href="https://phys.org/technology-news/machine-learning-ai/" target="_blank" rel="noopener noreferrer">Phys.org</a>; academic departments such as <a href="https://bair.berkeley.edu/blog/" target="_blank" rel="noopener noreferrer">BAIR</a>, <a href="https://oatml.cs.ox.ac.uk/blog.html" target="_blank" rel="noopener noreferrer">OATML</a>, <a href="https://mila.quebec/en/blog/" target="_blank" rel="noopener noreferrer">MILA</a>, <a href="https://blog.ml.cmu.edu/category/deep-learning/" target="_blank" rel="noopener noreferrer">ML@CMU</a>, <a href="http://ai.stanford.edu/blog/" target="_blank" rel="noopener noreferrer">Stanford AI Lab</a>, <a href="https://www.csail.mit.edu/research/center-brains-minds-and-machines" target="_blank" rel="noopener noreferrer">CSAIL</a>; leaders such as <a href="https://twitter.com/goodfellow_ian" target="_blank" rel="noopener noreferrer">@goodfellow_ian</a>, <a href="https://twitter.com/ylecun" target="_blank" rel="noopener norefrer">@ylecun</a>, <a href="https://twitter.com/karpathy" target="_blank" rel="noopener noreferrer">@karpathy</a>, <a href="https://twitter.com/JeffDean" target="_blank" rel="noopener noreferrer">@jeffdean</a>, <a href="https://twitter.com/fchollet" target="_blank" rel="noopener noreferrer">@fchollet</a>, <a href="https://twitter.com/fidlersanja?lang=en" target="_blank" rel="noopener noreferrer">@fidlersanja</a>, <a href="https://twitter.com/hugo_larochelle" target="_blank" rel="noopener noreferrer">@hugo_larochelle</a>, <a href="https://twitter.com/AnimaAnandkumar" target="_blank" rel="noopener noreferrer">@animaanandkumar</a>, <a href="https://twitter.com/NandoDF" target="_blank" rel="noopener noreferrer">@nandodf</a>, <a href="https://twitter.com/OriolVinyalsML" target="_blank" rel="noopener noreferrer">@oriolvinyalsml</a>, <a href="https://twitter.com/soumithchintala" target="_blank" rel="noopener norefrer">@soumithchintala</a>, <a href="https://twitter.com/drfeifei" target="_blank" rel="noopener noreferrer">@drfeifei</a>, and <a href="https://twitter.com/rsalakhu" target="_blank" rel="noopener noreferrer">@rsalakhu</a>. Connect with the people involved, <i>preferably graduate students</i> from academic departments of your interest, and build a mentor-to-mentee relationship; it is <i>crucial</i>. Your learning experience will be more focused, effective, and meaningful; eventually, you will develop the motivation and dedication to pursue scientific research.
         </p>

         <hr>
         <div class="wrapper">
            <blockquote class="rule">
               <p >&ensp;<i>‘‘Research is an exploration in the space of ideas.’’</i> - <a href="https://mila.quebec/en/person/bengio-yoshua/"target="_blank" rel="noopener noreferrer">@yoshuabengio</a>, <i>one of the architects of modern deep learning</i></p>
            </blockquote>
         </div>
         <hr>
         <p><b>Advanced frontiers:</b> As you build a foundation for research, you will observe that ‘<a href="https://paperswithcode.com/sota" target="_blank" rel="noopener noreferrer">state-of-the-art</a>’ in deep learning is a moving target and new developments in <a href="https://paperswithcode.com/area/computer-vision" target="_blank" rel="noopener noreferrer">computer vision</a>, <a href="https://paperswithcode.com/area/natural-language-processing" target="_blank" rel="noopener noreferrer">natural language processing</a>, <a href="https://paperswithcode.com/area/medical" target="_blank" rel="noopener noreferrer">bioinformatics</a>, <a href="https://paperswithcode.com/area/speech" target="_blank" rel="noopener noreferrer">speech systems</a>, and <a href="https://paperswithcode.com/area/robots" target="_blank" rel="noopener noreferrer">robotics</a> are constantly on the horizon. The interest in researching deep learning methodologies has given rise to ideas such as <a href="https://www.microsoft.com/en-us/research/blog/archai-can-design-your-neural-network-with-state-of-the-art-neural-architecture-search-nas/" target="_blank" rel="noopener noreferrer">neural architecture search</a>, <a href="http://www.bigcomputing.org/assets/files/DeepModelCompression-2.pdf" target="_blank" rel="noopener noreferrer">model compression</a>, <a href="https://thenextweb.com/neural/2020/09/03/tinyml-is-breathing-life-into-billions-of-devices/" target="_blank" rel="noopener noreferrer">edge-AI</a>, <a href="https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html" target="_blank" rel="noopener noreferrer">metalearning</a>, <a href="https://autogluon.mxnet.io" target="_blank" rel="noopener noreferrer">autoML</a>, <a href="https://www.youtube.com/watch?v=b187J4ndZWY" target="_blank" rel="noopener noreferrer">deep learning on graphs</a>, <a href="https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/transfer%20(v3).pdf" target="_blank" rel="noopener noreferrer">transfer learning</a>, <a href="http://www.eecs.umich.edu/eecs/pdfs/events/4142.pdf" target="_blank" rel="noopener noreferrer">domain adaptation</a>, <a href="https://christophm.github.io/interpretable-ml-book/adversarial.html" target="_blank" rel="noopener noreferrer">adversarial examples</a>, <a href="https://www.inovex.de/blog/uncertainty-quantification-deep-learning/" target="_blank" rel="noopener noreferrer">Bayesian learning</a>, and <a href="https://www.youtube.com/watch?v=8TTK-Dd0H9U" target="_blank" rel="noopener noreferrer">self-supervised learning</a>. The <a href="https://arxiv.org/pdf/1911.05289.pdf" target="_blank" rel="noopener noreferrer">trends in hardware development</a> have evolved and <a href="https://inst.eecs.berkeley.edu/~cs152/sp19/lectures/L20-DSA.pdf" target="_blank" rel="noopener noreferrer">TPUs</a>, <a href="https://www.graphcore.ai/products/ipu" target="_blank" rel="noopener noreferrer">IPUs</a> are enabling AI at scale through <a href="https://seal.ece.ucsb.edu/sites/default/files/publications/07924276.pdf" target="_blank" rel="noopener noreferrer">hardware+software co-design</a>. Modern deep learning research intersects a diverse range of concepts and ideas, even <a href="https://magenta.tensorflow.org/demos/" target="_blank" rel="noopener noreferrer">art and music</a>. As you learn, you will develop a unified mental model that connects these points. </p>
         <hr>
         <div class="wrapper">
            <blockquote class="rule">
               <p >&ensp;<i>‘‘The next revolution in AI will not be supervised, nor purely reinforced. It will be self-supervised.’’</i> - <a href="https://youtu.be/VsnQf7exv5I?t=3524"target="_blank" rel="noopener noreferrer">@yannlecun</a></p>
            </blockquote>
         </div>
         <hr>
         <p><b>Find your place:</b> 
            Self-learning is learning in a closed loop: you can build a solid foundation, but executing actual research may significantly depend on collaboration and supervision. For this, you need to connect to people involved in the area of your interest, and learn new ways of thinking from them. Interaction with people directly translates into interaction with ideas and consequently accelerates your growth. You should try to visit seminars, tutorials, and workshops; <a href="https://www.youtube.com/watch?v=eRXaQsDeC8U&list=PLgKuh-lKre10tATSWsRBweM6y-M0nyQ5U" target="_blank" rel="noopener noreferrer">webinars</a> are the new normal in current times. Events like <i><a href="https://vectorinstitute.ai/faq-items/2018-deep-learning-summer-school/" target="_blank" rel="noopener noreferrer">summer schools</a> and conferences are invaluable:</i> inclusion of experts from diverse fields collaborating on similar ideas with different approaches. Get involved with professors or students from their research groups and tune yourself with the process of research. <i>Try</i> to think about open problems: it’s a real challenge, and leads to a creative thought process, which is crucial for research.
         </p>
         <p><b>Execute research:</b> 
            Once you have developed a sufficient technical base, <i>you</i> may participate in <a href="http://matt.might.net/articles/phd-school-in-pictures/" target="_blank" rel="noopener noreferrer">pushing the boundaries</a> of deep learning and reshaping ‘state-of-the-art’. Join a research group as a resident or intern for summer research, for summer or winter schools, for senior thesis, or simply as a visitor. Build real experiences with real people and real problems. Down the line, a natural question would be to choose between academic research or industrial R&D. As evident, modern deep learning research spins out of collaborative efforts between industry and academia. As a future graduate student, you may pursue a PhD internship at Google, Facebook, or Nvidia; or as a researcher at DeepMind or OpenAI you may collaborate with universities; it’s your choice. As a starting point: work hard, build fundamentals, get in touch with people, apply for open positions, get selected, try solving research problems; repeat!
         </p>
         <p><b>Competitions:</b>
            Contests have channelled various breakthrough developments in the field. The representative example is ILSVRC 2012 that revolutionised the approaches to visual recognition and lead to an active research interest in CNNs. Several conferences such as <a href="https://neurips.cc/Conferences/2020/CompetitionTrack" target="_blank" rel="noopener noreferrer">NeurIPS</a>, <a href="https://sites.google.com/view/clvision2020/challenge" target="_blank" rel="noopener noreferrer">CVPR</a> and platforms such as <a href="https://competitions.codalab.org/" target="_blank" rel="noopener noreferrer">codalab</a> and <a href="https://l2rpn.chalearn.org/competitions" target="_blank" rel="noopener noreferrer">chalearn</a> host challenges to solve specific domain problems or to improve the performance of algorithms on specific class of tasks or datasets. 
         </p>
         <hr>
         <div class="mxgraph" style="max-width:100%;border:1px solid transparent; margin:auto;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers lightbox&quot;,&quot;xml&quot;:&quot;&lt;mxfile host=\&quot;app.diagrams.net\&quot; modified=\&quot;2020-10-12T09:31:39.280Z\&quot; agent=\&quot;5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\&quot; etag=\&quot;91vqOd22ACHDVaGMEbxR\&quot; version=\&quot;13.7.9\&quot; type=\&quot;device\&quot;&gt;&lt;diagram name=\&quot;Page-1\&quot; id=\&quot;ad52d381-51e7-2e0d-a935-2d0ddd2fd229\&quot;&gt;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&lt;/diagram&gt;&lt;/mxfile&gt;&quot;}"></div>
         <script type="text/javascript" src="https://viewer.diagrams.net/js/viewer-static.min.js"></script><br>
         <hr>
         <p><b>Interdisciplinary learning:</b> 
            The foundations of deep learning are built on applied mathematics with direct inspiration from neuroscience, physics, and electrical engineering: the field itself is the result of interdisciplinary exploration. Modern deep learning is transforming applications across several disciplines and driving new <a href="https://dl4sci-school.lbl.gov/" target="_blank" rel="noopener noreferrer">scientific practices</a> such as <a href="https://com-cog-book.github.io/com-cog-book/features/intro-com-mod-cog.html" target="_blank" rel="noopener noreferrer">computational models of cognition</a> inspired from artificial neural networks, use of <a href="https://indico.cern.ch/event/683620/contributions/3420614/attachments/1840352/3017035/Lab_Infieri_LabPresentation.pdf" target="_blank" rel="noopener noreferrer">transfer learning techniques</a>  for <a href="https://astroautomata.com/" target="_blank" rel="noopener noreferrer">astrophysics</a> data, optimizing <a href="https://www.frontiersin.org/articles/10.3389/fchem.2019.00809/full" target="_blank" rel="noopener noreferrer">chemical pattern predictions</a> in computational chemistry, and using reinforcement learning for <a href="https://arxiv.org/pdf/1812.08451.pdf" target="_blank" rel="noopener noreferrer">quantum error correction</a> or <a href="https://www.nature.com/articles/s41534-019-0141-3.pdf" target="_blank" rel="noopener noreferrer">quantum control</a>. It is an interesting aspect of research, and all intersecting disciplines drive each other forward. The representative example is <a href="https://media.nature.com/original/magazine-assets/d41586-019-02212-4/d41586-019-02212-4.pdf" target="_blank" rel="noopener noreferrer">artificial intelligence and neuroscience</a>. This symbiosis may encourage you to learn fundamental sciences alongside information and computing sciences. 
         </p>
         <p><b>Personal thoughts:</b> 
            Through my experience and learning, I have come across beautiful examples of deep learning’s interplay with physics, mathematics, and biology; and this deepened my fundamental scientific thinking. For example, provably hard combinatorial optimization problems such as maximum-cut studied in theoretical computer science can be approached through (i) probabilistic methods based on <a href="https://www.youtube.com/watch?v=9YNwif8tTKw" target="_blank" rel="noopener noreferrer">graph neural networks</a>; (ii) <a href="https://arxiv.org/pdf/2003.03600.pdf" target="_blank" rel="noopener noreferrer">reinforcement learning</a>; (iii) <a href="https://www.cs.umd.edu/class/fall2018/cmsc657/projects/group_16.pdf" target="_blank" rel="noopener noreferrer">variational algorithms</a> in quantum computing; (iv) <a href="https://dl.acm.org/doi/pdf/10.5555/2955239.2955306" target="_blank" rel="noopener noreferrer">evolutionary algorithms</a>, and (v) traditional <a href="http://www-math.mit.edu/~goemans/PAPERS/maxcut-jacm.pdf" target="_blank" rel="noopener noreferrer">algorithmic techniques</a>. Similarly, the <a href="http://faculty.uml.edu/vbarsegov/teaching/bioinformatics/lectures/ProteinFoldingModified.pdf" target="_blank" rel="noopener noreferrer">protein folding problem</a> particularly suited for <a href="https://physicsworld.com/a/quantum-approach-reveals-faster-protein-folding/" target="_blank" rel="noopener noreferrer">quantum computing</a> is also approached via <a href="https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery" target="_blank" rel="noopener noreferrer">deep learning</a>, and opens up new possibilities in quantum machine learning. The emergence or discovery of intimate connections between disparate fields is a characteristic of science and motivates us to consciously observe our universe.
         </p>
         <hr>
         <p><b>Remarks:</b>
            This letter aims to be the <i>first introduction</i> to research aspects of deep learning and does not include <i>many</i> important ideas and developments. As you progress through the field and explore further, you will discover <i>many</i> fascinating ideas within and beyond deep learning. This letter does not cover the issues within deep learning, such as the nature of intelligence, theoretical inconsistencies, interpretability; and practical issues such as <a href="https://www.cs.cornell.edu/~shmat/shmat_ccs15.pdf"target="_blank" rel="noopener noreferrer">privacy preservation</a>, <a href="https://arxiv.org/pdf/1909.11573.pdf"target="_blank" rel="noopener noreferrer">deepfakes</a>, bias, AI ethics, or <a href="https://spectrum.ieee.org/energywise/artificial-intelligence/machine-learning/energy-efficient-green-ai-strategies"target="_blank" rel="noopener noreferrer">energy efficiency</a>. However, these issues need to be addressed in research. It should also be emphasized that other machine learning techniques are of primal importance in research as well as in practical applications. You <i>must</i> cover machine learning in its entirety. As this letter builds on a research perspective, it significantly differs from production-level aspects such as software engineering or cloud deployment. 
         </p>
         <hr>
         <p><b>Endnotes:</b>
            All the resources referred in this letter are free, open-access, and available online; single exception is the <a href="https://www.springer.com/gp/book/9783319944623" target="_blank" rel="noopener noreferrer">Springer textbook</a> that is free only via institutional access. The hyperlinks are placed at relevant points and redirect to <i>important</i> literature items. I have also created a condensed presentation that summarizes this article. If you are actually interested in following through this learning path, please get in touch at <i><a href="mailto:lakshya@abstractions.dev">lakshya@abstractions.dev</a></i>. It could turn out to be a mutual learning experience for both of us. If this letter helps you, please share it with interested learners. Have a deep learning!
         </p>
         <hr>
         <div class="wrapper">
            <blockquote class="rule">
               <p>&ensp;&ensp;<i>‘‘Don't minimize mistakes. Minimize repeat mistakes. Fail in new ways and learn.’’</i> - <a href="https://lexfridman.com/"target="_blank" rel="noopener noreferrer">@lexfridman</a></p>
            </blockquote>
         </div>
         <hr>
         <p> 
            Please provide your valued feedback, suggestions, comments, or criticism via filling this survey form or write to me at <i><a href="mailto:feedback@abstractions.dev">feedback@abstractions.dev</a></i>. If you are interested in recieving future communications (blogs) from me about computer science, please mark your email here. I look forward to connecting with you.
         <hr>
         <br>
         <a href="//www.dmca.com/Protection/Status.aspx?ID=49894968-6317-4e4a-94a6-d9b2da83263c" title="DMCA.com Protection Status" class="dmca-badge"> <img src ="https://images.dmca.com/Badges/dmca-badge-w100-5x1-07.png?ID=49894968-6317-4e4a-94a6-d9b2da83263c"  alt="DMCA.com Protection Status" /></a>  <script src="https://images.dmca.com/Badges/DMCABadgeHelper.min.js"> </script> <a href="https://twitter.com/abstractionsdev?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @abstractionsdev</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
         <p class="validation">
            Thank you for your visit. This article is written by <a href="https://in.linkedin.com/in/lakshyapriyadarshi"target="_blank" rel="noopener noreferrer">Lakshya Priyadarshi</a> <script language="Javascript">
               document.write("and was last modified on " + document.lastModified +" IST");
            </script>
         </p>
      </div>
      <script type="text/javascript">
         var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
         document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
      </script>
      <script type="text/javascript">
         try {
         var pageTracker = _gat._getTracker("UA-12698422-1");
         pageTracker._trackPageview();
         } catch(err) {}
      </script>
   </body>
</html>